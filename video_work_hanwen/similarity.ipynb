{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "865"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./dict_sentences_per_verb_rachel1.json', 'r') as f:\n",
    "    dict_sentences = json.load(f)\n",
    "clean_sentences = []\n",
    "# clean_sentences = dict_sentences['cleaning']\n",
    "for k in dict_sentences.keys():\n",
    "    clean_sentences1 = dict_sentences[k]\n",
    "    clean_sentences += clean_sentences1\n",
    "len(clean_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cleaning', 'clean ', 'cleaned'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_sentences.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.DataFrame.from_dict(clean_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>time_s</th>\n",
       "      <th>time_e</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and i am going to bring that back to the bathr...</td>\n",
       "      <td>0:01:54.159000</td>\n",
       "      <td>0:02:06.079000</td>\n",
       "      <td>MC3HoMuc8os</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sometimes i am up early before everybody else ...</td>\n",
       "      <td>0:02:57.920000</td>\n",
       "      <td>0:03:05.280000</td>\n",
       "      <td>CGD3cTu_PrQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we have breakfast either byron or myself does ...</td>\n",
       "      <td>0:04:51.680000</td>\n",
       "      <td>0:05:12.560000</td>\n",
       "      <td>CGD3cTu_PrQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and everybody can get their schoolwork done an...</td>\n",
       "      <td>0:05:21.120000</td>\n",
       "      <td>0:05:30.639000</td>\n",
       "      <td>CGD3cTu_PrQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and then i turn it off if i am gonna leave the...</td>\n",
       "      <td>0:02:24</td>\n",
       "      <td>0:02:30.640000</td>\n",
       "      <td>6feNX6hc-44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>now you are going to be putting this into the ...</td>\n",
       "      <td>0:01:55.320000</td>\n",
       "      <td>0:02:16.620000</td>\n",
       "      <td>4ES4nNtbcNU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>so it does not boil over but the concept is th...</td>\n",
       "      <td>0:02:10.410000</td>\n",
       "      <td>0:02:22.650000</td>\n",
       "      <td>4ES4nNtbcNU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>but maybe you ve been feeling in a funk and yo...</td>\n",
       "      <td>0:02:38.530000</td>\n",
       "      <td>0:02:48.819000</td>\n",
       "      <td>YqDXju9CKFo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>is my chocolate I could have cleaned fold upon...</td>\n",
       "      <td>0:07:05.539000</td>\n",
       "      <td>0:07:21.110000</td>\n",
       "      <td>H0uN52lZH4k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>they are really good with their exchange polic...</td>\n",
       "      <td>0:12:45.670000</td>\n",
       "      <td>0:12:57.550000</td>\n",
       "      <td>BeJKu_r0wHY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>865 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence          time_s  \\\n",
       "0    and i am going to bring that back to the bathr...  0:01:54.159000   \n",
       "1    sometimes i am up early before everybody else ...  0:02:57.920000   \n",
       "2    we have breakfast either byron or myself does ...  0:04:51.680000   \n",
       "3    and everybody can get their schoolwork done an...  0:05:21.120000   \n",
       "4    and then i turn it off if i am gonna leave the...         0:02:24   \n",
       "..                                                 ...             ...   \n",
       "860  now you are going to be putting this into the ...  0:01:55.320000   \n",
       "861  so it does not boil over but the concept is th...  0:02:10.410000   \n",
       "862  but maybe you ve been feeling in a funk and yo...  0:02:38.530000   \n",
       "863  is my chocolate I could have cleaned fold upon...  0:07:05.539000   \n",
       "864  they are really good with their exchange polic...  0:12:45.670000   \n",
       "\n",
       "             time_e        video  \n",
       "0    0:02:06.079000  MC3HoMuc8os  \n",
       "1    0:03:05.280000  CGD3cTu_PrQ  \n",
       "2    0:05:12.560000  CGD3cTu_PrQ  \n",
       "3    0:05:30.639000  CGD3cTu_PrQ  \n",
       "4    0:02:30.640000  6feNX6hc-44  \n",
       "..              ...          ...  \n",
       "860  0:02:16.620000  4ES4nNtbcNU  \n",
       "861  0:02:22.650000  4ES4nNtbcNU  \n",
       "862  0:02:48.819000  YqDXju9CKFo  \n",
       "863  0:07:21.110000  H0uN52lZH4k  \n",
       "864  0:12:57.550000  BeJKu_r0wHY  \n",
       "\n",
       "[865 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    and i am going to bring that back to the bathr...\n",
       "time_s                                         0:01:54.159000\n",
       "time_e                                         0:02:06.079000\n",
       "video                                             MC3HoMuc8os\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./miniclips.json', 'r') as f:\n",
    "#     cleaning_outputs_old = json.load(f)\n",
    "# df2 = pd.DataFrame.from_dict(cleaning_outputs_old)\n",
    "# df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n",
      "l1fy6YbZDOs_0:04:44_0:04:51.mp4\n",
      "ed93-q7sfaw_0:00:48_0:00:54.mp4\n",
      "Zuu2hg3zEWE_0:05:08_0:05:22.mp4\n",
      "o3NuPI6CG6I_0:02:55_0:03:09.mp4\n",
      "sbUGABAfVDk_0:01:12_0:01:22.mp4\n",
      "99qybznkl3o_0:02:42_0:02:52.mp4\n",
      "TlHYvAMImck_0:00:25_0:00:42.mp4\n",
      "xGrH1SEzPPE_0:02:37_0:02:45.mp4\n",
      "hWTVnisq4A4_0:00:37_0:00:44.mp4\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "video_list = os.listdir('./miniclips')\n",
    "with open('./miniclips.json', 'r') as f:\n",
    "    cleaning_outputs = json.load(f)\n",
    "print(len(cleaning_outputs))\n",
    "cleaning_outputs_new = []\n",
    "for cleaning_output in cleaning_outputs:\n",
    "    video = cleaning_output['video']\n",
    "    result = cleaning_output['result']\n",
    "    video_name = video[:11]\n",
    "#     start = video[12:19]\n",
    "    start_striptime = time.strptime(video[12:19],'%H:%M:%S')\n",
    "    start = datetime.timedelta(hours=start_striptime.tm_hour,minutes=start_striptime.tm_min,seconds=start_striptime.tm_sec).total_seconds()\n",
    "#     end = video[20:27]\n",
    "    end_striptime = time.strptime(video[20:27],'%H:%M:%S')\n",
    "    end = datetime.timedelta(hours=end_striptime.tm_hour,minutes=end_striptime.tm_min,seconds=end_striptime.tm_sec).total_seconds()\n",
    "    \n",
    "    df2 = df1[df1['video'] == video_name]\n",
    "#     print(df2.shape[0])\n",
    "    duration = float(\"inf\")\n",
    "    index = -1\n",
    "    for i in range(df2.shape[0]):\n",
    "        time_s_striptime = time.strptime(df2.iloc[i]['time_s'][:7],'%H:%M:%S')\n",
    "        time_s = datetime.timedelta(hours=time_s_striptime.tm_hour,minutes=time_s_striptime.tm_min,seconds=time_s_striptime.tm_sec).total_seconds()\n",
    "\n",
    "        time_e_striptime =time.strptime(df2.iloc[i]['time_e'][:7],'%H:%M:%S')\n",
    "        time_e = datetime.timedelta(hours=time_e_striptime.tm_hour,minutes=time_e_striptime.tm_min,seconds=time_e_striptime.tm_sec).total_seconds()\n",
    "\n",
    "        min_time = min(start, time_s)\n",
    "        max_time = max(end, time_e)\n",
    "#         print(start, end, time_s, time_e)\n",
    "        if duration > max_time - min_time:\n",
    "            duration = max_time - min_time\n",
    "            index = i\n",
    "    if index == -1:\n",
    "        print(video)\n",
    "#         print(duration)\n",
    "    if index > -1:\n",
    "        cleaning_output['sentence'] = df2.iloc[index]['sentence']\n",
    "        cleaning_outputs_new.append(cleaning_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaning_outputs_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video': 'oOezuKHCPqo_0:06:16_0:07:04.mp4',\n",
       " 'result': [{'label': 'weaving basket', 'score': 0.20924896001815796},\n",
       "  {'label': 'cutting pineapple', 'score': 0.15751194953918457},\n",
       "  {'label': 'folding napkins', 'score': 0.052349746227264404},\n",
       "  {'label': 'arranging flowers', 'score': 0.0255792997777462},\n",
       "  {'label': 'stretching arm', 'score': 0.017990995198488235}],\n",
       " 'sentence': 'but if you are more of a diffuser type of person I also like a blend for the fall orange clove cinnamon and vanilla are a good combination and it is also going to make your entire bathroom smell so delicious and also get you in that cozy fall spirit so perfect for chilly fall nights once the bathroom is decluttered and cleaned and it feels like a spa you just want to add those finishing touches which is what I do lay out some fresh towels maybe a fresh robe and get everything ready so that when I am done with the hustle and bustle of the day'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_outputs_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hwmiao/deviate/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "cleaning_outputs1 = []\n",
    "for cleaning_output in cleaning_outputs_new:\n",
    "    similarities = []\n",
    "    transcript_emb = nlp(cleaning_output['sentence'])\n",
    "    for predict in cleaning_output['result']:\n",
    "        label = predict['label']\n",
    "        score = predict['score']\n",
    "        action_emb = nlp(label)\n",
    "        similarity = round(transcript_emb.similarity(action_emb), 2)\n",
    "        similarities.append((similarity, score))\n",
    "    cleaning_output['similarity'] = similarities\n",
    "    cleaning_outputs1.append(cleaning_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video': 'oOezuKHCPqo_0:06:16_0:07:04.mp4',\n",
       " 'result': [{'label': 'weaving basket', 'score': 0.20924896001815796},\n",
       "  {'label': 'cutting pineapple', 'score': 0.15751194953918457},\n",
       "  {'label': 'folding napkins', 'score': 0.052349746227264404},\n",
       "  {'label': 'arranging flowers', 'score': 0.0255792997777462},\n",
       "  {'label': 'stretching arm', 'score': 0.017990995198488235}],\n",
       " 'sentence': 'but if you are more of a diffuser type of person I also like a blend for the fall orange clove cinnamon and vanilla are a good combination and it is also going to make your entire bathroom smell so delicious and also get you in that cozy fall spirit so perfect for chilly fall nights once the bathroom is decluttered and cleaned and it feels like a spa you just want to add those finishing touches which is what I do lay out some fresh towels maybe a fresh robe and get everything ready so that when I am done with the hustle and bustle of the day',\n",
       " 'similarity': [(0.31, 0.20924896001815796),\n",
       "  (0.31, 0.15751194953918457),\n",
       "  (0.18, 0.052349746227264404),\n",
       "  (0.15, 0.0255792997777462),\n",
       "  (0.37, 0.017990995198488235)]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_outputs1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_list = os.listdir('./miniclips')\n",
    "# with open('./miniclips.json', 'r') as f:\n",
    "#     cleaning_outputs_old = json.load(f)\n",
    "# cleaning_outputs = dict()\n",
    "# for cleaning_output in cleaning_outputs_old:\n",
    "#     video = cleaning_output['video']\n",
    "#     result = cleaning_output['result']\n",
    "#     cleaning_outputs[video] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cleaning_output in cleaning_outputs:\n",
    "#     video = cleaning_output['video']\n",
    "#     video_name = video[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairs = []\n",
    "# for i in range(len(clean_sentences)):\n",
    "#     sentence = clean_sentences[i]['sentence']\n",
    "#     time_s = clean_sentences[i]['time_s'][:7]\n",
    "#     time_e = clean_sentences[i]['time_e'][:7]\n",
    "#     video = clean_sentences[i]['video']\n",
    "#     video_name = video + '_' + time_s + '_' + time_e + '.mp4'\n",
    "#     if video_name in video_list:\n",
    "#         predict_results = cleaning_outputs[video_name]\n",
    "#         predict_labels = []\n",
    "#         for predict_result in predict_results:\n",
    "#             label = predict_result['label']\n",
    "#             predict_labels.append(label)\n",
    "#         pairs.append((sentence, predict_labels))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('and i am getting the chores done i am cleaning up the kitchen i am getting ready of course we have breakfast',\n",
       " ['laying bricks',\n",
       "  'feeding goats',\n",
       "  'cooking chicken',\n",
       "  'bee keeping',\n",
       "  'cooking egg'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hwmiao/deviate/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/hwmiao/deviate/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/hwmiao/deviate/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/hwmiao/deviate/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/hwmiao/deviate/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/hwmiao/deviate/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hwmiao/deviate/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "similarities = []\n",
    "transcript_emb = nlp(pairs[0][0])\n",
    "for label in pairs[0][1]:\n",
    "    action_emb = nlp(label)\n",
    "    similarity = round(transcript_emb.similarity(action_emb), 2)\n",
    "    similarities.append(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.19, 0.22, 0.22, 0.26, 0.26]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hwmiao/deviate/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "all_similarities = []\n",
    "for pair in pairs:\n",
    "    transcript = pair[0]\n",
    "    transcript_emb = nlp(transcript)\n",
    "    predict_labels = pair[1]\n",
    "    similarities = []\n",
    "    for label in predict_labels:\n",
    "        action_emb = nlp(label)\n",
    "        similarity = round(transcript_emb.similarity(action_emb), 2)\n",
    "        similarities.append(similarity)\n",
    "    all_similarities.append((transcript, predict_labels, similarities))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('and i am getting the chores done i am cleaning up the kitchen i am getting ready of course we have breakfast',\n",
       " ['laying bricks',\n",
       "  'feeding goats',\n",
       "  'cooking chicken',\n",
       "  'bee keeping',\n",
       "  'cooking egg'],\n",
       " [0.19, 0.22, 0.22, 0.26, 0.26])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_similarities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('we were looking at the globe a lot with oliver so i am cleaning up the fireplace mantle and i am going to slowly start to bring in my fall decor',\n",
       " ['plastering',\n",
       "  'laying bricks',\n",
       "  'making bed',\n",
       "  'spray painting',\n",
       "  'contact juggling'],\n",
       " [0.22, 0.14, 0.19, 0.27, 0.3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_similarities[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i am on the phone with my mother in law so always getting a little chit chatting in while i am cleaning the house but i have to do a several passes on these windows because they get super super dirty and it is very streaky',\n",
       " ['cleaning windows',\n",
       "  'front raises',\n",
       "  'stretching arm',\n",
       "  'exercising arm',\n",
       "  'juggling balls'],\n",
       " [0.23, 0.24, 0.33, 0.3, 0.17])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_similarities[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('and then I am pulling the laundry from my kids bunk beds because that needs to be done and then very last but least I am cleaning the rugs that people step on when they enter my home those are the dirtiest so that is why always do that the last',\n",
       " ['using computer',\n",
       "  'playing controller',\n",
       "  'drumming fingers',\n",
       "  'unboxing',\n",
       "  'playing keyboard'],\n",
       " [0.08, 0.09, 0.18, 0.11, 0.11])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_similarities[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I noticed that people open the windows more in the summer months especially in the morning when the weather is nice and cool and also in the evenings so that is why am cleaning out we live on a ranch surrounded by ranches as well lots of horses kicking up dust that end up in my windows flies end up in my windows kind of gross',\n",
       " ['cleaning windows',\n",
       "  'stretching arm',\n",
       "  'front raises',\n",
       "  'exercising arm',\n",
       "  'punching bag'],\n",
       " [0.26, 0.1, 0.31, 0.1, 0.18])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_similarities[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('so that is why am vacuuming everything up getting it nice and clean and then I am cleaning up the windows screens and the glass on the windows as well to make sure it is enticing to open the windows so that is why usually close the windows in the middle of the day but',\n",
       " ['cleaning windows',\n",
       "  'stretching arm',\n",
       "  'exercising arm',\n",
       "  'stretching leg',\n",
       "  'yoga'],\n",
       " [0.25, 0.08, 0.1, 0.13, -0.04])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_similarities[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('our trash day is on Thursday so on Friday mornings I usually bring that in okay so back into the kitchen I am cleaning up the kitchen from like I said having family come and stay with us',\n",
       " ['playing paintball',\n",
       "  'archery',\n",
       "  'tossing salad',\n",
       "  'arranging flowers',\n",
       "  'throwing axe'],\n",
       " [0.34, 0.25, 0.26, 0.15, 0.38])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_similarities[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('so there is some stuff in my kitchen that is out that normally is not out when it is the four of us so that is why am cleaning all that up I am going to put the wine glasses away put everything back and',\n",
       " ['tossing salad',\n",
       "  'cooking chicken',\n",
       "  'making tea',\n",
       "  'breading or breadcrumbing',\n",
       "  'grinding meat'],\n",
       " [0.11, 0.02, 0.13, 0.1, 0.1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_similarities[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('so there is always something that falls behind the little pull out especially on the bottom there is like a reason or nuts or a cheese it or something back there so I am cleaning all that out and then I am also going sweep the floor',\n",
       " ['cleaning floor',\n",
       "  'mopping floor',\n",
       "  'sanding floor',\n",
       "  'sweeping floor',\n",
       "  'building cabinet'],\n",
       " [0.2, 0.21, 0.12, 0.15, 0.18])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_similarities[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('full te we are trying to get as many chores and projects done as possible and also maintaining my normal cleaning schedule so today I am cleaning the entire house and when I clean the entire house since I do have a little bit of a bigger house I try to do more surface level level cleaning unless I want to do detailed cleaning and if I want to do detail cleaning',\n",
       " ['blasting sand',\n",
       "  'cleaning floor',\n",
       "  'shining shoes',\n",
       "  'curling hair',\n",
       "  'sanding floor'],\n",
       " [0.49, 0.52, 0.35, 0.5, 0.43])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_similarities[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
